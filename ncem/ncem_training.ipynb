{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc367222",
   "metadata": {},
   "source": [
    "# Training NCEM to find interaction resolution\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09105501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ncem\n",
    "#from ncem.data import get_data_custom, customLoader\n",
    "\n",
    "import squidpy as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcb935",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This notebook uses the same AnnData object as our interpretation notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4c18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = sq.datasets.mibitof()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0997b9d",
   "metadata": {},
   "source": [
    "We now call the NCEM trainer for the intaction model and initialize it. The data was already pre-processed, so we set the `log_transform` argument to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fdad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ncem.train.TrainModelInteractions()\n",
    "trainer.init_estim(log_transform=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84451134",
   "metadata": {},
   "source": [
    "Next, we call the `customLoader` in ncem on the AnnData object and specify the radius we want to train the model on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538d67fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ncem' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mncem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mcustomLoader(\n\u001b[1;32m      2\u001b[0m     adata\u001b[38;5;241m=\u001b[39mad, cluster\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m, patient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdonor\u001b[39m\u001b[38;5;124m'\u001b[39m, library_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibrary_id\u001b[39m\u001b[38;5;124m'\u001b[39m, radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m52\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m ncem\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget_data_custom(interpreter\u001b[38;5;241m=\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mestimator)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ncem' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "trainer.estimator.data = ncem.data.customLoader(\n",
    "    adata=ad, cluster='Cluster', patient='donor', library_id='library_id', radius=52\n",
    ")\n",
    "ncem.data.get_data_custom(interpreter=trainer.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea5ccd",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "As a next step, we initialize the model. For this step, we need to specify `n_eval_nodes_per_graph`, so the number of nodes per graph that are passed through the network in each forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.estimator.init_model(n_eval_nodes_per_graph=10)\n",
    "trainer.estimator.model.training_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c0193",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We now train the model for 10 epochs. Usually, we would train for arround 2000 epochs to ensure the model converges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75888efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.estimator.train(epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda6b705",
   "metadata": {},
   "source": [
    "We trained NCEM on this dataset before in an ablation study for multiple different radii and resolution paramaters. We inspected that the model performs best at a resolution of approximately 10 $\\mu m$ and that performance drops again at larger distances. \n",
    "\n",
    "![title](images/ablation_hartmann.png)\n",
    "\n",
    "In general, we recommend to test a few resolution parameters to ensure convergence of NCEM and before running the type coupling analysis for the best distance. In this way, one can ensure that interactions extracted are valuable and provide vmeaningful insight into putative sender-receiver dependencies. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
